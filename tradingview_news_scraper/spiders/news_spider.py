import time

import scrapy
from scrapy.utils.project import get_project_settings
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, NoSuchElementException

import json
import os
from dotenv import load_dotenv
import requests
from urllib.parse import urljoin, urlparse
from datetime import datetime

class TradingViewNewsSpider(scrapy.Spider):
    name = 'tradingview_news'
    start_urls = ['https://www.tradingview.com/accounts/signin/'] # Loginé é¢
    
    def __init__(self, *args, **kwargs):
        super(TradingViewNewsSpider, self).__init__(*args, **kwargs)
        # è¨­ç½®Chromeé¸é …
        chrome_options = Options()
        chrome_options.add_argument('--headless=new')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        #chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument("--window-size=1200,8000")
        #chrome_options.add_argument("--start-fullscreen")
        chrome_options.add_argument("--force-device-scale-factor=0.1")
        
        # åˆå§‹åŒ–WebDriver
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.wait = WebDriverWait(self.driver, 10)
        
        # XPATHè·¯å¾‘é…ç½® - è«‹åœ¨æ­¤è™•å¡«å…¥æ‚¨çš„XPATH
        self.xpaths = {
            # ç™»å…¥é é¢å…ƒç´ 
            'email_button': '/html/body/div[3]/div/div/div[1]/div/div[2]/div[2]/div/div/button',  # Emailç™»å…¥æŒ‰éˆ•
            'username_field': '//*[@id="id_username"]',  # ç”¨æˆ¶åè¼¸å…¥æ¡†
            'password_field': '//*[@id="id_password"]',  # å¯†ç¢¼è¼¸å…¥æ¡†
            'login_button': '/html/body/div[3]/div/div/div[1]/div/div[2]/div[2]/div/div/div/form/button',  # ç™»å…¥æŒ‰éˆ•
            
            # æ–°èé é¢å…ƒç´ 
            'news_list': '//*[@id="news-screener-page"]/div/div/div/div[1]/div/div[2]/div[2]/div[2]/div',  # æ–°èåˆ—è¡¨å®¹å™¨çš„XPATH
            'news_items': '//*[@id="news-screener-page"]/div/div/div/div[1]/div/div[2]/div[2]/div[2]/div/a',  # æ–°èé …ç›®çš„XPATHï¼ˆå¯é»æ“Šçš„é€£çµï¼‰
            'right_panel': '//*[@id="news-screener-page"]/div/div/div/div[3]',  # å³å´é¢æ¿çš„XPATH
            'panel_title': '//*[@id="news-screener-page"]/div/div/div/div[3]/div/div/div/div/article/h2',  # å³å´é¢æ¿æ¨™é¡Œçš„XPATH
            'panel_content': '//*[@id="news-screener-page"]/div/div/div/div[3]/div/div/div/div/article/div[3]/div/div[1]/div[2]/span',  # å³å´é¢æ¿å…§å®¹çš„XPATH
            'panel_symbols': '//*[@id="news-screener-page"]/div/div/div/div[3]/div/div/div/div/article/div[3]/div/div[1]/div[1]',  # å³å´é¢æ¿ç¬¦è™Ÿçš„XPATH
            'close_button': '',  # é—œé–‰æŒ‰éˆ•çš„XPATHï¼ˆå¯é¸ï¼‰
            'list_title': '//*[@id="news-screener-page"]/div/div/div/div[1]/div/div[2]/div[2]/div[2]/div/a[1]/article/div/div'  # åˆ—è¡¨ä¸­æ¨™é¡Œçš„XPATHï¼ˆç›¸å°æ–¼news_itemsï¼‰
        }
        
        # ç™»å…¥æ†‘è­‰ - è«‹è¨­ç½®æ‚¨çš„ç™»å…¥è³‡è¨Š
        load_dotenv()
        self.credentials = {
            'username': os.getenv('USERNAME'),
            'password': os.getenv('PASSWORD')
        }
        
        

        # åˆå§‹åŒ–Markdownè¼¸å‡º
        self.markdown_content = []
        self.output_filename = f'tradingview_news_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
        
        # å‰µå»ºåœ–ç‰‡ä¿å­˜ç›®éŒ„
        self.images_dir = f'images_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
        os.makedirs(self.images_dir, exist_ok=True)
        
        # åœ–ç‰‡ä¸‹è¼‰è¨­ç½®
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def parse(self, response):
        """ä¸»è¦è§£æå‡½æ•¸ - å¾ç™»å…¥é é¢é–‹å§‹"""
        self.driver.get(response.url)
        
        try:
            # åŸ·è¡Œè‡ªå‹•ç™»å…¥
            if self.perform_login():
                self.logger.info("ç™»å…¥æˆåŠŸï¼Œå°å‘æ–°èé é¢")
                # å°å‘æ–°èé é¢
                news_url = 'https://www.tradingview.com/news-flow/?symbol=BINANCE:BTCUSDT'
                self.driver.get(news_url)
                
                # é–‹å§‹æ–°èçˆ¬å–æµç¨‹
                self.scrape_news()
            else:
                self.logger.error("ç™»å…¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒçˆ¬å–")
                return
                
        except Exception as e:
            self.logger.error(f"çˆ¬å–éç¨‹ä¸­å‡ºéŒ¯: {str(e)}")
        
        # ä¿å­˜Markdownæ–‡ä»¶
        self.save_markdown_file()
    
    def perform_login(self):
        """åŸ·è¡Œè‡ªå‹•ç™»å…¥"""
        try:
            self.logger.info("é–‹å§‹åŸ·è¡Œè‡ªå‹•ç™»å…¥...")
            
            # æª¢æŸ¥ç™»å…¥æ†‘è­‰
            if not self.credentials['username'] or not self.credentials['password']:
                self.logger.error("è«‹åœ¨ credentials ä¸­è¨­ç½®ç”¨æˆ¶åå’Œå¯†ç¢¼")
                return False
            
            # ç­‰å¾…é é¢åŠ è¼‰
            time.sleep(1.5)
            
            # 1. é»æ“ŠEmailç™»å…¥æŒ‰éˆ•
            email_button = self.wait.until(
                EC.element_to_be_clickable((By.XPATH, self.xpaths['email_button']))
            )
            email_button.click()
            self.logger.info("å·²é»æ“ŠEmailç™»å…¥æŒ‰éˆ•")
            time.sleep(1)
            
            # 2. å¡«å…¥ç”¨æˆ¶å
            username_field = self.wait.until(
                EC.presence_of_element_located((By.XPATH, self.xpaths['username_field']))
            )
            username_field.clear()
            username_field.send_keys(self.credentials['username'])
            self.logger.info("å·²å¡«å…¥ç”¨æˆ¶å")
            
            # 3. å¡«å…¥å¯†ç¢¼
            password_field = self.driver.find_element(By.XPATH, self.xpaths['password_field'])
            password_field.clear()
            password_field.send_keys(self.credentials['password'])
            self.logger.info("å·²å¡«å…¥å¯†ç¢¼")
            
            # 4. é»æ“Šç™»å…¥æŒ‰éˆ•
            login_button = self.driver.find_element(By.XPATH, self.xpaths['login_button'])
            login_button.click()
            self.logger.info("å·²é»æ“Šç™»å…¥æŒ‰éˆ•")
            
            # ç­‰å¾…ç™»å…¥å®Œæˆ - æª¢æŸ¥æ˜¯å¦è·³è½‰åˆ°ä¸»é é¢
            time.sleep(5)
            
            # æª¢æŸ¥æ˜¯å¦ç™»å…¥æˆåŠŸï¼ˆå¯ä»¥é€šéURLè®ŠåŒ–æˆ–ç‰¹å®šå…ƒç´ ä¾†åˆ¤æ–·ï¼‰
            current_url = self.driver.current_url
            if 'signin' not in current_url:
                self.logger.info("ç™»å…¥æˆåŠŸï¼")
                return True
            else:
                self.logger.error("ç™»å…¥å¤±æ•—ï¼Œä»åœ¨ç™»å…¥é é¢")
                return False
                
        except TimeoutException:
            self.logger.error("ç™»å…¥é é¢å…ƒç´ åŠ è¼‰è¶…æ™‚")
            return False
        except Exception as e:
            self.logger.error(f"ç™»å…¥éç¨‹ä¸­å‡ºéŒ¯: {str(e)}")
            return False
    
    def scrape_news(self):
        """çˆ¬å–æ–°èçš„ä¸»è¦æµç¨‹"""
        # åˆå§‹åŒ–Markdownæ–‡ä»¶æ¨™é¡Œ
        self.markdown_content.append(f"# TradingView BTCUSDT æ–°èå ±å‘Š\n")
        self.markdown_content.append(f"**çˆ¬å–æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        self.markdown_content.append(f"**ä¾†æº**: {self.driver.current_url}\n\n")
        self.markdown_content.append("---\n\n")
        
        try:
            # ç­‰å¾…æ–°èåˆ—è¡¨åŠ è¼‰
            if self.xpaths['news_list']:
                self.wait.until(EC.presence_of_element_located((By.XPATH, self.xpaths['news_list'])))
                self.logger.info("æ–°èåˆ—è¡¨åŠ è¼‰å®Œæˆ")
            
            # æ»¾å‹•é é¢ä»¥åŠ è¼‰æ›´å¤šæ–°è
            self.scroll_and_load_news()
            
            # ç²å–æ‰€æœ‰æ–°èé …ç›®
            if not self.xpaths['news_items']:
                self.logger.error("è«‹è¨­ç½® news_items çš„XPATHè·¯å¾‘")
                return
                
            news_items = self.driver.find_elements(By.XPATH, self.xpaths['news_items'])
            self.logger.info(f"æ‰¾åˆ° {len(news_items)} æ¢æ–°è")
            
            # éæ­·æ¯å€‹æ–°èé …ç›®
            for index, news_item in enumerate(news_items):
                try:
                    # ç²å–æ–°èæ¨™é¡Œ
                    title = self.get_news_title(news_item)
                    
                    # é»æ“Šæ–°èé …ç›®
                    self.driver.execute_script("arguments[0].click();", news_item)
                    
                    # ç­‰å¾…å³å´é¢æ¿åŠ è¼‰
                    time.sleep(0.5)
                    
                    # æå–æ–°èè©³ç´°å…§å®¹
                    news_data = self.extract_news_details(title, index)
                    
                    if news_data:
                        # æ·»åŠ åˆ°Markdownå…§å®¹
                        self.add_to_markdown(news_data)
                        # å¦‚æœéœ€è¦yieldæ•¸æ“šçµ¦Scrapyæ¡†æ¶ï¼Œå¯ä»¥åœ¨é€™è£¡æ·»åŠ 
                    
                    # é—œé–‰å³å´é¢æ¿
                    self.close_right_panel()
                    
                except Exception as e:
                    self.logger.error(f"è™•ç†ç¬¬ {index+1} æ¢æ–°èæ™‚å‡ºéŒ¯: {str(e)}")
                    continue
                    
        except TimeoutException:
            self.logger.error("æ–°èé é¢åŠ è¼‰è¶…æ™‚")
        except Exception as e:
            self.logger.error(f"çˆ¬å–æ–°èéç¨‹ä¸­å‡ºéŒ¯: {str(e)}")
    
    def scroll_and_load_news(self):
        """æ»¾å‹•é é¢åŠ è¼‰æ›´å¤šæ–°è"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        
        while True:
            # æ»¾å‹•åˆ°é é¢åº•éƒ¨
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)  # ç­‰å¾…åŠ è¼‰
            
            # è¨ˆç®—æ–°çš„é é¢é«˜åº¦
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height:
                break
                
            last_height = new_height
        
        self.logger.info("å®Œæˆæ»¾å‹•åŠ è¼‰")
    
    def get_news_title(self, news_item):
        """ç²å–æ–°èæ¨™é¡Œ"""
        try:
            if self.xpaths['list_title']:
                # ä½¿ç”¨ç›¸å°XPATHæŸ¥æ‰¾æ¨™é¡Œ
                title_element = news_item.find_element(By.XPATH, self.xpaths['list_title'])
                title = title_element.text.strip()
                if title:
                    return title
            
            # å¦‚æœæ²’æœ‰è¨­ç½®XPATHæˆ–æ‰¾ä¸åˆ°ï¼Œè¿”å›å…ƒç´ æ–‡æœ¬
            return news_item.text.strip() or "ç„¡æ¨™é¡Œ"
            
        except Exception as e:
            self.logger.error(f"ç²å–æ¨™é¡Œæ™‚å‡ºéŒ¯: {str(e)}")
            return "ç„¡æ¨™é¡Œ"
    
    def extract_news_details(self, title, index):
        """æå–æ–°èè©³ç´°å…§å®¹"""
        try:
            # ç­‰å¾…å³å´é¢æ¿å‡ºç¾
            if not self.xpaths['right_panel']:
                self.logger.error("è«‹è¨­ç½® right_panel çš„XPATHè·¯å¾‘")
                return None
                
            right_panel = self.wait.until(
                EC.presence_of_element_located((By.XPATH, self.xpaths['right_panel']))
            )
            
            # æå–æ¨™é¡Œï¼ˆå¾å³å´é¢æ¿ï¼‰
            panel_title = self.extract_panel_title()
            
            # æå–å…§å®¹å’Œåœ–ç‰‡
            content_data = self.extract_content()
            
            # æå–ç›¸é—œç¬¦è™Ÿ
            symbols = self.extract_symbols()
            
            news_data = {
                'index': index + 1,
                'list_title': title,  # åˆ—è¡¨ä¸­çš„æ¨™é¡Œ
                'panel_title': panel_title,  # å³å´é¢æ¿ä¸­çš„æ¨™é¡Œ
                'content': content_data['text'],  # æ–‡æœ¬å…§å®¹
                'images': content_data['images'],  # åœ–ç‰‡ä¿¡æ¯
                'symbols': symbols,
                'url': self.driver.current_url
            }
            
            self.logger.info(f"æˆåŠŸæå–ç¬¬ {index+1} æ¢æ–°è: {panel_title[:50]}... (åŒ…å« {len(content_data['images'])} å¼µåœ–ç‰‡)")
            return news_data
            
        except TimeoutException:
            self.logger.error(f"ç¬¬ {index+1} æ¢æ–°èå³å´é¢æ¿åŠ è¼‰è¶…æ™‚")
            return None
        except Exception as e:
            self.logger.error(f"æå–ç¬¬ {index+1} æ¢æ–°èè©³æƒ…æ™‚å‡ºéŒ¯: {str(e)}")
            return None
    
    def extract_panel_title(self):
        """å¾å³å´é¢æ¿æå–æ¨™é¡Œ"""
        try:
            if self.xpaths['panel_title']:
                title_element = self.driver.find_element(By.XPATH, self.xpaths['panel_title'])
                return title_element.text.strip()
            else:
                self.logger.warning("æœªè¨­ç½® panel_title çš„XPATHè·¯å¾‘")
                return "ç„¡æ¨™é¡Œ"
        except NoSuchElementException:
            self.logger.warning("ä½¿ç”¨XPATHæœªæ‰¾åˆ°æ¨™é¡Œå…ƒç´ ")
            return "ç„¡æ¨™é¡Œ"
        except Exception as e:
            self.logger.error(f"æå–é¢æ¿æ¨™é¡Œæ™‚å‡ºéŒ¯: {str(e)}")
            return "ç„¡æ¨™é¡Œ"
    
    def extract_content(self):
        """æå–æ–°èå…§å®¹ä¸¦ä¸‹è¼‰åœ–ç‰‡"""
        try:
            if self.xpaths['panel_content']:
                # æ”¯æŒå–®å€‹æˆ–å¤šå€‹å…§å®¹å…ƒç´ 
                content_elements = self.driver.find_elements(By.XPATH, self.xpaths['panel_content'])
                
                contents = []
                images = []
                
                for element in content_elements:
                    # æå–æ–‡æœ¬å…§å®¹
                    text = element.text.strip()
                    if text and len(text) > 10:  # éæ¿¾æ‰å¤ªçŸ­çš„æ–‡æœ¬
                        contents.append(text)
                    
                    # æŸ¥æ‰¾ä¸¦ä¸‹è¼‰åœ–ç‰‡
                    img_elements = element.find_elements(By.TAG_NAME, 'img')
                    for img in img_elements:
                        image_info = self.download_image(img)
                        if image_info:
                            images.append(image_info)
                
                # å»é‡ä¸¦åˆä½µå…§å®¹
                unique_contents = list(dict.fromkeys(contents))  # ä¿æŒé †åºçš„å»é‡
                text_content = ' '.join(unique_contents) if unique_contents else "ç„¡å…§å®¹"
                
                # è¿”å›æ–‡æœ¬å…§å®¹å’Œåœ–ç‰‡ä¿¡æ¯
                return {
                    'text': text_content,
                    'images': images
                }
            else:
                self.logger.warning("æœªè¨­ç½® panel_content çš„XPATHè·¯å¾‘")
                return {
                    'text': "ç„¡å…§å®¹",
                    'images': []
                }
                
        except Exception as e:
            self.logger.error(f"æå–å…§å®¹æ™‚å‡ºéŒ¯: {str(e)}")
            return {
                'text': "ç„¡å…§å®¹",
                'images': []
            }
    
    def extract_symbols(self):
        """æå–ç›¸é—œç¬¦è™Ÿ"""
        try:
            if self.xpaths['panel_symbols']:
                symbol_elements = self.driver.find_elements(By.XPATH, self.xpaths['panel_symbols'])
                
                symbols = []
                for element in symbol_elements:
                    text = element.text.strip()
                    if text:
                        symbols.append(text)
                
                return list(set(symbols)) if symbols else []
            else:
                self.logger.warning("æœªè¨­ç½® panel_symbols çš„XPATHè·¯å¾‘")
                return []
                
        except Exception as e:
            self.logger.error(f"æå–ç¬¦è™Ÿæ™‚å‡ºéŒ¯: {str(e)}")
            return []
    
    def close_right_panel(self):
        """é—œé–‰å³å´é¢æ¿"""
        try:
            if self.xpaths['close_button']:
                # ä½¿ç”¨è¨­ç½®çš„é—œé–‰æŒ‰éˆ•XPATH
                close_btn = self.driver.find_element(By.XPATH, self.xpaths['close_button'])
                close_btn.click()
                time.sleep(0.5)
                return
            
            # å¦‚æœæ²’æœ‰è¨­ç½®é—œé–‰æŒ‰éˆ•XPATHï¼Œé»æ“Šé¢æ¿å¤–éƒ¨å€åŸŸ
            self.driver.execute_script("document.body.click();")
            time.sleep(0.5)
            
        except NoSuchElementException:
            # å¦‚æœæ‰¾ä¸åˆ°é—œé–‰æŒ‰éˆ•ï¼Œå˜—è©¦é»æ“Šé é¢å…¶ä»–å€åŸŸ
            self.driver.execute_script("document.body.click();")
            time.sleep(0.5)
        except Exception as e:
            self.logger.error(f"é—œé–‰å³å´é¢æ¿æ™‚å‡ºéŒ¯: {str(e)}")
    
    def download_image(self, img_element):
        """ä¸‹è¼‰åœ–ç‰‡ä¸¦è¿”å›åœ–ç‰‡ä¿¡æ¯"""
        try:
            # ç²å–åœ–ç‰‡URL
            img_src = img_element.get_attribute('src')
            if not img_src:
                return None
            
            # è™•ç†ç›¸å°URL
            if img_src.startswith('//'):
                img_src = 'https:' + img_src
            elif img_src.startswith('/'):
                img_src = urljoin('https://www.tradingview.com', img_src)
            
            # ç²å–åœ–ç‰‡altæ–‡æœ¬ä½œç‚ºæè¿°
            img_alt = img_element.get_attribute('alt') or 'image'
            
            # ç”Ÿæˆæ–‡ä»¶å
            parsed_url = urlparse(img_src)
            file_extension = os.path.splitext(parsed_url.path)[1] or '.jpg'
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # æ¯«ç§’ç´šæ™‚é–“æˆ³
            filename = f"image_{timestamp}{file_extension}"
            filepath = os.path.join(self.images_dir, filename)
            
            # ä¸‹è¼‰åœ–ç‰‡
            response = self.session.get(img_src, timeout=10)
            response.raise_for_status()
            
            # ä¿å­˜åœ–ç‰‡
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            self.logger.info(f"åœ–ç‰‡å·²ä¸‹è¼‰: {filename}")
            
            return {
                'filename': filename,
                'filepath': filepath,
                'url': img_src,
                'alt': img_alt,
                'size': len(response.content)
            }
            
        except Exception as e:
            self.logger.error(f"ä¸‹è¼‰åœ–ç‰‡æ™‚å‡ºéŒ¯: {str(e)}")
            return None
    
    def add_to_markdown(self, news_data):
        """å°‡æ–°èæ•¸æ“šæ·»åŠ åˆ°Markdownå…§å®¹ä¸­"""
        try:
            self.markdown_content.append(f"## {news_data['index']}. {news_data['panel_title']}\n\n")
            
            # å¦‚æœåˆ—è¡¨æ¨™é¡Œèˆ‡é¢æ¿æ¨™é¡Œä¸åŒï¼Œé¡¯ç¤ºåˆ—è¡¨æ¨™é¡Œ
            if news_data['list_title'] != news_data['panel_title'] and news_data['list_title'] != "ç„¡æ¨™é¡Œ":
                self.markdown_content.append(f"**Provider**: {news_data['list_title']}\n\n")
            
            # æ–°èå…§å®¹
            if news_data['content'] and news_data['content'] != "ç„¡å…§å®¹":
                self.markdown_content.append(f"**å…§å®¹**:\n{news_data['content']}\n\n")
            
            # åœ–ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if news_data.get('images') and len(news_data['images']) > 0:
                self.markdown_content.append(f"**åœ–ç‰‡** ({len(news_data['images'])} å¼µ):\n\n")
                for i, img in enumerate(news_data['images'], 1):
                    # æ·»åŠ åœ–ç‰‡åˆ°Markdown
                    self.markdown_content.append(f"{i}. ![{img['alt']}]({img['filepath']})\n")
                    if img['alt'] and img['alt'] != 'image':
                        self.markdown_content.append(f"   - æè¿°: {img['alt']}\n")
                    self.markdown_content.append(f"   - æ–‡ä»¶: `{img['filename']}`\n")
            
            # ç›¸é—œç¬¦è™Ÿ
            if news_data['symbols']:
                symbols_text = ", ".join([f"`{symbol}`" for symbol in news_data['symbols']])
                self.markdown_content.append(f"**ç›¸é—œç¬¦è™Ÿ**: {symbols_text}\n\n")
            
            # ä¾†æºé€£çµ
            if news_data['url']:
                self.markdown_content.append(f"**ä¾†æº**: [TradingView]({news_data['url']})\n\n")
            
            self.markdown_content.append("---\n\n")
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ Markdownå…§å®¹æ™‚å‡ºéŒ¯: {str(e)}")
    
    def save_markdown_file(self):
        """ä¿å­˜Markdownæ–‡ä»¶"""
        try:
            # è¨ˆç®—ç¸½åœ–ç‰‡æ•¸é‡
            total_images = sum([len(line.split('![')) - 1 for line in self.markdown_content if '![' in line])
            
            # æ·»åŠ æ–‡ä»¶çµå°¾
            self.markdown_content.append(f"\n---\n")
            self.markdown_content.append(f"**å ±å‘Šç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            self.markdown_content.append(f"**ç¸½å…±çˆ¬å–**: {len([line for line in self.markdown_content if line.startswith('## ')])} æ¢æ–°è\n")
            self.markdown_content.append(f"**ç¸½å…±ä¸‹è¼‰**: {total_images} å¼µåœ–ç‰‡\n")
            self.markdown_content.append(f"**åœ–ç‰‡ä¿å­˜ç›®éŒ„**: `{self.images_dir}/`\n")
            
            # å¯«å…¥æ–‡ä»¶
            with open(self.output_filename, 'w', encoding='utf-8') as f:
                f.writelines(self.markdown_content)
            
            self.logger.info(f"Markdownæ–‡ä»¶å·²ä¿å­˜: {self.output_filename}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜Markdownæ–‡ä»¶æ™‚å‡ºéŒ¯: {str(e)}")
    
    def closed(self, reason):
        """çˆ¬èŸ²çµæŸæ™‚é—œé–‰ç€è¦½å™¨"""
        self.driver.quit()
        self.session.close()  # é—œé–‰requests session
        self.logger.info("ç€è¦½å™¨å·²é—œé–‰")
        self.logger.info(f"Markdownå ±å‘Šå·²ä¿å­˜è‡³: {self.output_filename}")
        self.logger.info(f"åœ–ç‰‡å·²ä¿å­˜è‡³ç›®éŒ„: {self.images_dir}/")


# é‹è¡Œè…³æœ¬
if __name__ == "__main__":
    # å‰µå»º Scrapy è¨­ç½®
    from scrapy.crawler import CrawlerProcess
    from scrapy.utils.project import get_project_settings
    
    # è¨­ç½®è¼¸å‡ºæ ¼å¼ - ä¿ç•™JSONä½œç‚ºå‚™ä»½
    settings = get_project_settings()
    settings.set('FEEDS', {
        'tradingview_news_backup.json': {
            'format': 'json',
            'encoding': 'utf8',
            'store_empty': False,
            'fields': ['index', 'list_title', 'panel_title', 'content', 'images', 'symbols', 'url'],
            'indent': 2
        }
    })
    
    # è¨­ç½®ç”¨æˆ¶ä»£ç†
    settings.set('USER_AGENT', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    
    # è¨­ç½®ä¸‹è¼‰å»¶é²
    settings.set('DOWNLOAD_DELAY', 1)
    settings.set('RANDOMIZE_DOWNLOAD_DELAY', True)
    
    # å‰µå»ºçˆ¬èŸ²é€²ç¨‹
    process = CrawlerProcess(settings)
    process.crawl(TradingViewNewsSpider)
    process.start()
    
    print(f"\nâœ… çˆ¬å–å®Œæˆï¼")
    print(f"ğŸ“„ Markdownå ±å‘Šå·²ä¿å­˜")
    print(f"ğŸ–¼ï¸ åœ–ç‰‡å·²ä¿å­˜è‡³ç›®éŒ„")
    print(f"ğŸ’¾ JSONå‚™ä»½æ–‡ä»¶: tradingview_news_backup.json")